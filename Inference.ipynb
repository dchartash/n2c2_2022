{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8e9368-6aed-40cd-aa81-dac4c61cb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import spacy\n",
    "import sklearn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Value, ClassLabel, Features, DatasetDict\n",
    "from datasets import load_metric\n",
    "import evaluate\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "from transformers import GPT2Tokenizer, GPTNeoForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import logging\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from transformers import RobertaForSequenceClassification, BertForSequenceClassification\n",
    "\n",
    "from preprocessing.cleaning_utils import *\n",
    "from train_utils.metrics import *\n",
    "from train_utils.plot_utils import *\n",
    "from train_utils.custom_trainer import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from train_utils.metrics import *\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14548f4-7224-4254-9285-9269e2208530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from datasets import Value, ClassLabel, Features, DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec7c7bc-26d0-4101-954c-79c3328855ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"/home/vs428/project/n2c2/2022/Data/n2c2_track3_test.csv\")\n",
    "# data = pd.read_csv()\n",
    "DATA_DIR = \"/home/vs428/project/n2c2/2022/Data/dev.csv\"\n",
    "OUTPUT_DIR = \"/home/vs428/Documents/n2c2_2022/outputs/2022-10-26/03-12-17/outputs/roberta_large/checkpoint-432\"\n",
    "BATCH_SIZE = 16\n",
    "SPACY_ASSESSMENT =  \"/home/vs428/project/n2c2_spacy_models/assessment_model_v2/model-best\"\n",
    "SPACY_PLAN =  \"/home/vs428/project/n2c2_spacy_models/plan_subsection_model_v3/model-best\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a348960f-bae5-4dd1-938d-7126b76a6b3e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(OUTPUT_DIR,\n",
    "                                                        num_labels=4)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/vs428/project/models/RoBERTa-large-PM-M3-Voc/RoBERTa-large-PM-M3-Voc-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833f0ace-ff25-41ab-a63e-5105786e63b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ysm/project/rtaylor/vs428/conda_envs/n2c2_env3/lib/python3.9/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp_assessment = spacy.load(SPACY_ASSESSMENT, exclude=\"parser\")\n",
    "nlp_plan = spacy.load(SPACY_PLAN, exclude=\"parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12493b2d-e80e-4024-b1f5-d116ad9f026a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-06b7106e5d40a705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/vs428/.cache/huggingface/datasets/csv/default-06b7106e5d40a705/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981deeb8dd8a49218ba12074c837c296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb9fd156c564dd5beacdafd368bba39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ysm/project/rtaylor/vs428/conda_envs/n2c2_env3/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:697: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/vs428/.cache/huggingface/datasets/csv/default-06b7106e5d40a705/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59591e480a304c0ba6e6c8425fd4df4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a947a789f54db2831d592cc29e2a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e27e33ce5642359c889d2429db2eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abf937787754371a4f47e62a45c1b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning the labels:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# create hf Dataset\n",
    "classes = ['Not Relevant', 'Neither', 'Indirect', 'Direct']\n",
    "\n",
    "# instead we will use the raw text for now\n",
    "features = Features({\n",
    "    'ROW ID':Value(\"int64\"),\n",
    "    'HADM ID':Value(\"int64\"),\n",
    "    'Assessment':Value(\"string\"),\n",
    "    'Plan Subsection':Value(\"string\"),\n",
    "    \"Relation\":Value(\"string\")\n",
    "}) \n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={\n",
    "                            \"train\":DATA_DIR,\n",
    "                        },\n",
    "                       features=features)\n",
    "\n",
    "# create encoded class labels and rename\n",
    "dataset = dataset.class_encode_column(\"Relation\")\n",
    "label2id = {'Not Relevant':3, 'Neither':2, 'Indirect':1, 'Direct':0}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "dataset = dataset.align_labels_with_mapping(label2id, \"Relation\")\n",
    "dataset = dataset.rename_column(\"Relation\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e649fe-4683-47c8-83f4-72b1db27af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cb0b08-4c7d-4c74-8ae3-751f37b98d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].select(range(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4da681c-2d77-477b-ac9f-c4d31f108d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1eff93-392c-4efb-b297-97a18df25a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b02c7ec3107470ba516b2b3baeb24d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7078e70d64d740de924ad24de745462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# add the named entities\n",
    "dataset = dataset.map(partial(add_ner_assessment, nlp=nlp_assessment))\n",
    "dataset = dataset.map(partial(add_ner_plan, nlp=nlp_plan))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2f1588-23f6-4e2d-9a2f-9e64d71b8f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50017, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# we ASSUME that the ner labels we want are lowercase, UNLIKE the standard ones in the model\n",
    "spans = [x for x in nlp_plan.get_pipe(\"ner\").labels if x.islower()] + [x for x in nlp_assessment.get_pipe(\"ner\").labels if x.islower()]\n",
    "\n",
    "tokens = []\n",
    "for span in spans:\n",
    "    tokens.append(\"<\" + span + \">\")\n",
    "    tokens.append(\"</\" + span + \">\")            \n",
    "\n",
    "# add the span tags to the vocab\n",
    "_ = tokenizer.add_tokens(tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c463a1-89b6-4fef-9dc5-b10af834f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create training args and Trainer\n",
    "test_args = TrainingArguments(output_dir=OUTPUT_DIR, \n",
    "                                    do_train = False,\n",
    "                                    do_predict = True,\n",
    "                                    evaluation_strategy=\"steps\",\n",
    "                                    learning_rate=1e-5,\n",
    "                                    load_best_model_at_end=True,\n",
    "                                    warmup_ratio = 0.06,\n",
    "                                    gradient_accumulation_steps = 8,\n",
    "                                    per_device_eval_batch_size = BATCH_SIZE,   \n",
    "                                    dataloader_drop_last = False,  \n",
    "                                    fp16=True,\n",
    "                                    log_level=\"debug\",\n",
    "                                    logging_dir=f\"./outputs/test\",\n",
    "                                    logging_strategy=\"steps\",\n",
    "                                    logging_first_step=True,\n",
    "                                    logging_steps=500,                                      \n",
    "                                    # save_steps=1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f76ed9e-d098-403d-99fb-4790ba0e0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2445/261045724.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  acc = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# metrics to track\n",
    "acc = load_metric(\"accuracy\")\n",
    "macrof1 = load_metric(\"f1\")    \n",
    "roc_auc_score = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "# create metric_dict for compute_metrics\n",
    "metric_dict = {}\n",
    "metric_dict['accuracy'] = {\"metric\":acc}\n",
    "metric_dict['f1-macro'] = {\"metric\":macrof1, \"average\":\"macro\"}\n",
    "metric_dict['auroc'] = {'metric':roc_auc_score, \"multi_class\":'ovr'}\n",
    "metric_dict['roc'] = {}\n",
    "metric_dict[\"pr\"] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c4cfbb-ce0b-4dec-83a0-710114bd9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778f4a35e2db4282918c6eba11e4b879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "<s>88 year old female with hx <secondary_problem>addison</secondary_problem>'s, <secondary_problem>PE</secondary_problem> [**2127**], <secondary_problem>HTN</secondary_problem>, <secondary_problem>mild AS</secondary_problem> s/p recent\n",
      "   femur fx and <secondary_problem>ORIF</secondary_problem> p/w <primary_symptom>fevers</primary_symptom>, <primary_sign>hypotension</primary_sign>, <primary_problem>PE</primary_problem> and <primary_symptom>elevated troponin</primary_symptom>\n",
      "   concerning for <primary_problem>sepsis</primary_problem> vs cardiogenic shock.\n",
      "  .</s></s><problem>Depression</problem>:\n",
      "   - hold qhs nortriptylline for drowsiness\n",
      "  .</s>\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "dataset = dataset.map(partial(tokenize_function, tokenizer=tokenizer), batched=True)\n",
    "print(tokenizer.decode(dataset[0]['input_ids']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7a37a2-032f-45af-a6c0-e938ca420544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ROW ID, Assessment, Plan Subsection, HADM ID.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cast as pytorch tensors and select a subset of columns we want\n",
    "\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# create collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer,\n",
    "                                        max_length=512, \n",
    "                                        padding=\"longest\",\n",
    "                                        return_tensors=\"pt\")    \n",
    "# create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    compute_metrics=partial(compute_metrics, metric_dict=metric_dict),\n",
    "    data_collator=data_collator,\n",
    ")    \n",
    "\n",
    "# predict for metrics\n",
    "metrics = trainer.predict(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27caee05-3e40-4b1f-b853-ba3b2db2ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr, tpr, roc_auc = metrics[2]['test_roc']\n",
    "precision, recall, ap = metrics[2]['test_pr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc53efd-5a78-4fc3-a10b-e551cdfed068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9412336085478388, 1: 0.88878096163186, 2: 0.9364035087719298, 3: 0.9939024390243902}\n",
      "{0: 0.8704608475399298, 1: 0.7379087539887257, 2: 0.845438509779852, 3: 0.9814814814814816}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(roc_auc), print(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f8b48d-2688-418a-9063-5e4c0da93eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2label {3: 'Not Relevant', 2: 'Neither', 1: 'Indirect', 0: 'Direct'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"id2label\", id2label)\n",
    "# plot_multiclass_roc(fpr, tpr, roc_auc, figsize=(8, 6), labels=id2label, fname=\"Eval_AUROC.png\")\n",
    "# plot_multiclass_pr(precision, recall, ap, figsize=(8, 6), labels=id2label, fname=\"Eval_AUPRC.png\")\n",
    "\n",
    "preds = np.argmax(metrics.predictions, axis=-1)\n",
    "\n",
    "# test_dataset['test'].to_csv(\"test_dataset_output.csv\")\n",
    "# np.savetxt(\"test_predictions.csv\", preds, delimiter=\",\")\n",
    "# np.savetxt(\"test_label_ids.csv\", predict_output.label_ids, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d951e4-8ac4-44fc-8a5d-4bcb9950d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5627cdb-4ea0-41a1-92cd-40f0bcc23603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0, 1, 3, 0, 0, 1, 3, 2, 1, 2, 0, 1, 2, 0, 3, 0, 2, 0, 0, 3,\n",
       "        0, 3, 1, 0, 1, 2, 0, 1, 1, 3, 1, 0, 0, 2, 2, 1, 0, 0, 3, 2, 2, 2,\n",
       "        2, 2, 0, 3, 1, 3, 2, 1, 3, 0, 2, 1, 1, 1, 1, 2, 1, 0, 3, 2, 1, 2,\n",
       "        1, 0, 1, 2, 2, 0, 0, 1, 1, 0, 3, 1, 0, 0, 3, 0, 0, 2, 3, 3, 1, 1,\n",
       "        0, 2, 1, 0, 3, 3, 0, 2, 1, 2, 3, 1]),\n",
       " array([2, 1, 0, 1, 3, 0, 0, 1, 3, 2, 1, 2, 0, 1, 2, 0, 3, 0, 2, 2, 0, 3,\n",
       "        0, 3, 2, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 3, 2, 2, 2,\n",
       "        2, 2, 1, 3, 2, 3, 2, 0, 3, 2, 2, 2, 0, 1, 1, 2, 1, 1, 3, 2, 2, 2,\n",
       "        1, 2, 1, 2, 2, 0, 0, 1, 0, 0, 3, 1, 0, 0, 3, 0, 0, 2, 3, 3, 1, 1,\n",
       "        0, 2, 1, 0, 3, 3, 2, 2, 1, 2, 3, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = dataset['label'].numpy()\n",
    "y_true, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebc733e1-0cb6-4f75-901c-cddd8987c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indirect_wrongs = np.where((y_true == 1) & (y_true != preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a18bfc41-e350-4c3c-bae9-cbcb733ee215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24, 32, 37, 48, 51, 55, 56, 64, 74, 99]),)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indirect_wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64851b5e-7456-4ca0-ab13-0391737bd8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, '<problem>Panic disorder</problem>: Valium prn CIWA')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSET_IDX = 35\n",
    "y_true[TSET_IDX], preds[TSET_IDX], dataset['Plan Subsection'][TSET_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6c5590a-737b-4783-b4e5-eb6ed9036e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24, 32, 37, 48, 51, 55, 56, 64, 74, 99]),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indirect_wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a433415f-fc80-414a-864d-c630644bf1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = indirect_wrongs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce001e22-5c86-4d3a-988e-fc98b53d2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_wrong_text = []\n",
    "for x in indirect_wrongs[0]:\n",
    "    indirect_wrong_text.append(dataset['Assessment'][x] + \"<SEP>\" + dataset['Plan Subsection'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ce1af27-dfff-4084-8771-c9c24073987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indirect_wrong_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0de5cb11-a894-4a65-91d1-d45b446a19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def drop_spacy_annotations(texts):\n",
    "    outs = []\n",
    "    for text in texts:\n",
    "        outs.append(re.sub(r'<\\/?secondary_problem>|<\\/?problem>|<\\/?primary_problem>|<\\/?primary_symptom>|<\\/?primary_sign>|<\\/?complication_related_to_problem>|<\\/?event_related_to_problem>|<\\/?organ_failure_related_to_problem>', \n",
    "                           '', text))\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0741d922-e1ec-4dd2-9904-038f819b5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_wrong_text_dropped = drop_spacy_annotations(indirect_wrong_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c769f0-e24e-43b8-bdc5-dbc3ac5e886d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['Assessment'])#[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "034c284a-9493-4a1d-b8bb-66ff6136d2b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. [**Known lastname 2891**] is a 43 y/o M with hx of <secondary_problem>HIV/AIDs</secondary_problem>, off HAART x 6 months\n",
      "   w/<secondary_problem>CDC 16</secondary_problem> presenting with <primary_symptom>fevers</primary_symptom>, <primary_symptom>dyspnea</primary_symptom> likely [**2-17**] <primary_problem>PCP</primary_problem>.<SEP><problem>Weight loss</problem> - likely multifactorial including <complication_related_to_problem>diarrhea</complication_related_to_problem>, <complication_related_to_problem>infection</complication_related_to_problem>,\n",
      "   AIDS.\n",
      "   -encourage po's\n",
      "   -likely further work up in outpatient setting.\n",
      "\n",
      "\n",
      "Mr. [**Known lastname 2891**] is a 43 y/o M with hx of HIV/AIDs, off HAART x 6 months\n",
      "   w/CDC 16 presenting with fevers, dyspnea likely [**2-17**] PCP.<SEP>Weight loss - likely multifactorial including diarrhea, infection,\n",
      "   AIDS.\n",
      "   -encourage po's\n",
      "   -likely further work up in outpatient setting.\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "ssessment and Plan: Pt is a 58 y.o female with h.o <secondary_problem>OSA</secondary_problem>, <secondary_problem>COPD</secondary_problem>, <secondary_problem>obesity</secondary_problem>,\n",
      "   <secondary_problem>DVT</secondary_problem>, <secondary_problem>MRSA PNA</secondary_problem> who presents with <primary_sign>hypoxia</primary_sign> and <primary_sign>epistaxsis</primary_sign>.<SEP>#<problem>chest pain</problem>-PT reported CP at OSH and was given asa and ativan.\n",
      "   Currently hypoxic. CTA negative for PE. Could be related to cardiac\n",
      "   cause, however EKG findigns and CE's unrevealing. Could be secondary to\n",
      "   pulmonary cause with the above findings. MSK/GI also possibilities. Pt\n",
      "   reports anxiety as the cause.\n",
      "   - ruled out MI, likely related to shortness of breath\n",
      "\n",
      "\n",
      "ssessment and Plan: Pt is a 58 y.o female with h.o OSA, COPD, obesity,\n",
      "   DVT, MRSA PNA who presents with hypoxia and epistaxsis.<SEP>#chest pain-PT reported CP at OSH and was given asa and ativan.\n",
      "   Currently hypoxic. CTA negative for PE. Could be related to cardiac\n",
      "   cause, however EKG findigns and CE's unrevealing. Could be secondary to\n",
      "   pulmonary cause with the above findings. MSK/GI also possibilities. Pt\n",
      "   reports anxiety as the cause.\n",
      "   - ruled out MI, likely related to shortness of breath\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "76 y/o female with <secondary_problem>MMP</secondary_problem> presenting with <primary_problem>melanotic stools</primary_problem>, <primary_symptom>coffee ground\n",
      "   emesis</primary_symptom> in setting of coagulopathy with INR 4.5 on admission. Given\n",
      "   <primary_symptom>coffee ground emesis</primary_symptom>, source is likely upper G.I, and may be due to\n",
      "   ulcer dx,<primary_problem>gastritis</primary_problem>, <primary_problem>AVM</primary_problem> or <primary_problem>cancer</primary_problem>.<SEP>Hx <problem>c.diff colitis</problem>. Day 11 of therapy, likely etiology white count.\n",
      "   Continue flagyl.\n",
      "\n",
      "\n",
      "76 y/o female with MMP presenting with melanotic stools, coffee ground\n",
      "   emesis in setting of coagulopathy with INR 4.5 on admission. Given\n",
      "   coffee ground emesis, source is likely upper G.I, and may be due to\n",
      "   ulcer dx,gastritis, AVM or cancer.<SEP>Hx c.diff colitis. Day 11 of therapy, likely etiology white count.\n",
      "   Continue flagyl.\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "ASSESSMENT AND PLAN: 78 y/o female with <secondary_problem>PMH</secondary_problem> of persistent <secondary_problem>atrial\n",
      "   fibrillation/flutter</secondary_problem>, <secondary_problem>chronic diastolic heart failure</secondary_problem> (EF 65%), <secondary_problem>DM2</secondary_problem>,\n",
      "   <secondary_problem>hypertension</secondary_problem> and <secondary_problem>dyslipidemia</secondary_problem> who presents from home with <primary_symptom>chest pain</primary_symptom>,\n",
      "   <primary_sign>bradycardia</primary_sign> and <primary_problem>AMS</primary_problem>, initially intubated with TVP. Now s/p PMP,\n",
      "   extubated, and doing well.<SEP># <problem>Leukocytosis</problem>: No focal signs of infection.  Could be secondary to\n",
      "   stress response.  All cell lines up suggestive of hemoconcentration.\n",
      "   Received Vanc/Zosyn in ED.  Blood and urine cultures sent in ED.  UA\n",
      "   negative. CXR without infiltrate. Currently afebrile.  Got fem line in\n",
      "   ED which was non-sterile.\n",
      "   - d/c\n",
      "ed fem line ASAP given placed non-sterile\n",
      "   - f/u cultures\n",
      "   - f/u final CXR read\n",
      "   - monitor fever curve, follow WBC\n",
      "   - no abx for now given no clear source\n",
      "   - Will pull Cordis today\n",
      "\n",
      "\n",
      "ASSESSMENT AND PLAN: 78 y/o female with PMH of persistent atrial\n",
      "   fibrillation/flutter, chronic diastolic heart failure (EF 65%), DM2,\n",
      "   hypertension and dyslipidemia who presents from home with chest pain,\n",
      "   bradycardia and AMS, initially intubated with TVP. Now s/p PMP,\n",
      "   extubated, and doing well.<SEP># Leukocytosis: No focal signs of infection.  Could be secondary to\n",
      "   stress response.  All cell lines up suggestive of hemoconcentration.\n",
      "   Received Vanc/Zosyn in ED.  Blood and urine cultures sent in ED.  UA\n",
      "   negative. CXR without infiltrate. Currently afebrile.  Got fem line in\n",
      "   ED which was non-sterile.\n",
      "   - d/c\n",
      "ed fem line ASAP given placed non-sterile\n",
      "   - f/u cultures\n",
      "   - f/u final CXR read\n",
      "   - monitor fever curve, follow WBC\n",
      "   - no abx for now given no clear source\n",
      "   - Will pull Cordis today\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "37 y/o with <secondary_problem>DM</secondary_problem> presents from OSH after presenting in <primary_problem>septic shock</primary_problem> with\n",
      "   <primary_problem>Staph PNA / bacteria</primary_problem> with a course complicated by <primary_problem>ARF</primary_problem> and <primary_sign>tachycardia</primary_sign>,\n",
      "   currently remains intubated but off pressors since [**2117-10-28**]. <secondary_problem>Staph</secondary_problem> in\n",
      "   blood/sputum (OSH), <secondary_problem>GNR</secondary_problem> in blood, <secondary_problem>klebsiella</secondary_problem> in sputum.\n",
      "   .<SEP><problem>Tachycardia/</problem> <problem>AFib</problem>: appeared sinus on arrival, then through his course\n",
      "   had couple runs of tachycardia that appeared to be Afib with aberrancy\n",
      "   that were self-limited and well-tolerated.   OSH EKG with RBBB as\n",
      "   recently as [**10-26**], and reports of atrial fibrillation requiring\n",
      "   treatment with diltiazem.  Several days ago, went into AFib w/ RVR\n",
      "   during dialysis.  Treated w/ lopressor 10, dilt 20 IV and dilt PO60.\n",
      "   Converted back to sinus after 1-2 hours. <complication_related_to_problem>Atrial irritation believed due\n",
      "   to</complication_related_to_problem> IJ that was too deep, now pulled back.  Cause of aberrant SVT during\n",
      "   second HD session likely due to intracellular shifts, although cause\n",
      "   not clear.\n",
      "   - Dilt stopped and lopressor started again according to cardiology recs\n",
      "   - Dose of lopressor 12.5 TID, will increase tomorrow if needed.\n",
      "   - 24 hour amiodarone will be done at 1430\n",
      "   - Watch hemodynamics and rhythm\n",
      "   .\n",
      "\n",
      "\n",
      "37 y/o with DM presents from OSH after presenting in septic shock with\n",
      "   Staph PNA / bacteria with a course complicated by ARF and tachycardia,\n",
      "   currently remains intubated but off pressors since [**2117-10-28**]. Staph in\n",
      "   blood/sputum (OSH), GNR in blood, klebsiella in sputum.\n",
      "   .<SEP>Tachycardia/ AFib: appeared sinus on arrival, then through his course\n",
      "   had couple runs of tachycardia that appeared to be Afib with aberrancy\n",
      "   that were self-limited and well-tolerated.   OSH EKG with RBBB as\n",
      "   recently as [**10-26**], and reports of atrial fibrillation requiring\n",
      "   treatment with diltiazem.  Several days ago, went into AFib w/ RVR\n",
      "   during dialysis.  Treated w/ lopressor 10, dilt 20 IV and dilt PO60.\n",
      "   Converted back to sinus after 1-2 hours. Atrial irritation believed due\n",
      "   to IJ that was too deep, now pulled back.  Cause of aberrant SVT during\n",
      "   second HD session likely due to intracellular shifts, although cause\n",
      "   not clear.\n",
      "   - Dilt stopped and lopressor started again according to cardiology recs\n",
      "   - Dose of lopressor 12.5 TID, will increase tomorrow if needed.\n",
      "   - 24 hour amiodarone will be done at 1430\n",
      "   - Watch hemodynamics and rhythm\n",
      "   .\n",
      "Predicted: Direct\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "37 y/o with <secondary_problem>DM</secondary_problem> presents from OSH after presenting in <primary_problem>septic shock</primary_problem> with\n",
      "   <primary_problem>Staph PNA / bacteria</primary_problem> with a course complicated by <primary_problem>ARF</primary_problem> and <primary_sign>tachycardia</primary_sign>,\n",
      "   currently remains intubated but off pressors since [**2117-10-28**]. <secondary_problem>Staph</secondary_problem> in\n",
      "   blood/sputum (OSH), <secondary_problem>GNR</secondary_problem> in blood, <secondary_problem>klebsiella</secondary_problem> in sputum.\n",
      "   .<SEP><problem>Mild LFT elevation</problem>: likely [**1-4**] prolonged hypotension.\n",
      "   - Continue to trend daily LFTs\n",
      "   - Limit tylenol to 2 gm daily\n",
      "\n",
      "\n",
      "37 y/o with DM presents from OSH after presenting in septic shock with\n",
      "   Staph PNA / bacteria with a course complicated by ARF and tachycardia,\n",
      "   currently remains intubated but off pressors since [**2117-10-28**]. Staph in\n",
      "   blood/sputum (OSH), GNR in blood, klebsiella in sputum.\n",
      "   .<SEP>Mild LFT elevation: likely [**1-4**] prolonged hypotension.\n",
      "   - Continue to trend daily LFTs\n",
      "   - Limit tylenol to 2 gm daily\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "63 year old male with <secondary_problem>ETOH abuse</secondary_problem> and history of <secondary_problem>withdrawal seizures</secondary_problem> and\n",
      "   <secondary_problem>DTs</secondary_problem> presenting with <primary_problem>ETOH withdrawal</primary_problem><SEP><problem>Seizure</problem>: Does not sound like seizure occurred, since pt was\n",
      "   conscious and responsive, lactate normal, no post-ictal state.\n",
      "   - seizure precautions\n",
      "\n",
      "\n",
      "63 year old male with ETOH abuse and history of withdrawal seizures and\n",
      "   DTs presenting with ETOH withdrawal<SEP>Seizure: Does not sound like seizure occurred, since pt was\n",
      "   conscious and responsive, lactate normal, no post-ictal state.\n",
      "   - seizure precautions\n",
      "Predicted: Direct\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "ASSESSMENT AND PLAN: 78 y/o female with <secondary_problem>PMH</secondary_problem> of persistent <secondary_problem>atrial\n",
      "   fibrillation/flutter</secondary_problem>, <secondary_problem>chronic diastolic heart failure</secondary_problem> (EF 65%), <secondary_problem>DM2</secondary_problem>,\n",
      "   <secondary_problem>hypertension</secondary_problem> and <secondary_problem>dyslipidemia</secondary_problem> who presents from home with <primary_symptom>chest pain</primary_symptom>,\n",
      "   <primary_sign>bradycardia</primary_sign> and <primary_problem>AMS</primary_problem>, initially intubated with TVP. Now s/p PMP,\n",
      "   extubated, and doing well.<SEP># <problem>Hyperkalemia</problem>: K on admission 6.1, down to 4.6 by the afternoon.\n",
      "   Received 4 amps calcium gluconate in ED.  Was on ACE and\n",
      "   potassium-sparing diuretic at home which likely contributing to <complication_related_to_problem>acute\n",
      "   elevation in K.</complication_related_to_problem>  Also with ARF which is also contributing.  Not\n",
      "   acidotic.\n",
      "   - Received kayexalate, insulin, D50, bibarb with good effect\n",
      "   - Vomited up kayexalate while intubated. No obvious aspiration\n",
      "   - Holding ACE and spironolactone.\n",
      "\n",
      "\n",
      "ASSESSMENT AND PLAN: 78 y/o female with PMH of persistent atrial\n",
      "   fibrillation/flutter, chronic diastolic heart failure (EF 65%), DM2,\n",
      "   hypertension and dyslipidemia who presents from home with chest pain,\n",
      "   bradycardia and AMS, initially intubated with TVP. Now s/p PMP,\n",
      "   extubated, and doing well.<SEP># Hyperkalemia: K on admission 6.1, down to 4.6 by the afternoon.\n",
      "   Received 4 amps calcium gluconate in ED.  Was on ACE and\n",
      "   potassium-sparing diuretic at home which likely contributing to acute\n",
      "   elevation in K.  Also with ARF which is also contributing.  Not\n",
      "   acidotic.\n",
      "   - Received kayexalate, insulin, D50, bibarb with good effect\n",
      "   - Vomited up kayexalate while intubated. No obvious aspiration\n",
      "   - Holding ACE and spironolactone.\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "51 y/o male with a history of <secondary_problem>severe mixed obstructive and restrictive\n",
      "   disease</secondary_problem> recently admitted with <primary_problem>hypoxic and hypercarbic respiratory\n",
      "   failure</primary_problem>, <secondary_problem>VAP</secondary_problem> and <secondary_problem>ARF</secondary_problem> now readmitted with <primary_problem>hypercarbic respiratory\n",
      "   failure</primary_problem>, <primary_sign>hypotension</primary_sign>, and <primary_symptom>elevated INR</primary_symptom>.<SEP><problem>PNEUMONIA</problem>, <problem>BACTERIAL</problem>, VENTILATOR ACQUIRED (VAP)\n",
      "\n",
      "\n",
      "51 y/o male with a history of severe mixed obstructive and restrictive\n",
      "   disease recently admitted with hypoxic and hypercarbic respiratory\n",
      "   failure, VAP and ARF now readmitted with hypercarbic respiratory\n",
      "   failure, hypotension, and elevated INR.<SEP>PNEUMONIA, BACTERIAL, VENTILATOR ACQUIRED (VAP)\n",
      "Predicted: Direct\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "Assesment: This is a 64 year-old female with a history of <secondary_problem>Hodgkins\n",
      "   lymphoma</secondary_problem> s/p SCT x 2, <secondary_problem>CHF</secondary_problem> with EF 30%, <secondary_problem>transfusion dependent MDS</secondary_problem>,\n",
      "   admitted for <primary_sign>febrile neutropenia</primary_sign> now transferred to the [**Hospital Unit Name 1**] with\n",
      "   <primary_symptom>altered mental status</primary_symptom>.<SEP># <problem>CAD</problem>:\n",
      "   - hold metoprolol and valsartan\n",
      "   - no aspirin given thrombocytopenia\n",
      "\n",
      "\n",
      "Assesment: This is a 64 year-old female with a history of Hodgkins\n",
      "   lymphoma s/p SCT x 2, CHF with EF 30%, transfusion dependent MDS,\n",
      "   admitted for febrile neutropenia now transferred to the [**Hospital Unit Name 1**] with\n",
      "   altered mental status.<SEP># CAD:\n",
      "   - hold metoprolol and valsartan\n",
      "   - no aspirin given thrombocytopenia\n",
      "Predicted: Neither\n",
      "True: Indirect\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDX2 = list(zip(range(len(indirect_wrongs[0])), indirect_wrongs[0]))#[(0,0),(1,7),(2,8),]# (1,10), (2,16), (3, 32), (4, 34)]\n",
    "IDX1 = 1\n",
    "for x, y in IDX2:\n",
    "    print(indirect_wrong_text[x]), print(\"\\n\"), print(indirect_wrong_text_dropped[x]), print(f\"Predicted: {id2label[preds[y]]}\"), print(f\"True: {id2label[1]}\")\n",
    "    print(\"\\n\\n-----------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7925bf7-e558-4a62-9f36-90e93e6ce65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b8a69dc-6e13-4480-82d8-92cda09db90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=13)\n",
    "fig.suptitle('Validation Set Confusion Matrix', fontsize=20, weight=\"bold\")\n",
    "plt.xlabel('Predicted Label', fontsize=16, weight=\"bold\")\n",
    "plt.ylabel('True Label', fontsize=16, weight=\"bold\")\n",
    "# plt.tight_layout()\n",
    "ConfusionMatrixDisplay.from_predictions(dataset['label'].numpy(), preds, ax=ax, display_labels=['Direct', 'Indirect', 'Neither', 'Not Relevant'])\n",
    "plt.savefig(\"conf.png\",dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682e7de-754d-4369-91f8-0a3fcda725ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b88121-5e12-4eb9-b2a8-399a8be6c1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26862a5a-eaad-4694-bdc4-1a809bbbae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2ad38-831e-45c6-af40-497fa32df2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e271a3a-ad9c-4c36-889c-eeb0f11e4a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb065e-4ff3-48ad-8c46-9b721bfcbbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
