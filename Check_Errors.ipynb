{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c34218f5-cc82-4a7d-bf4b-de0d719fc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "from functools import partial\n",
    "from train_utils.metrics import *\n",
    "\n",
    "from preprocessing.cleaning_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb70d55-39ef-4635-8536-a51974f4f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Value, ClassLabel, Features, DatasetDict\n",
    "from datasets import load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32750a9e-541e-46f7-853e-5764766d6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43cb95c-34e8-43da-b78f-7e373535fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = \"/home/vs428/Documents/n2c2_2022/outputs/2022-06-28/12-20-30/test_trainer/checkpoint-9500\"\n",
    "\n",
    "assessment_model_f = \"/home/vs428/Documents/prodigy/assessment_model/model-best\"\n",
    "plan_model_f = \"/home/vs428/Documents/prodigy/plan_subsection_model/model-best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc0e518-79f7-482c-b27a-f098c22d205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")\n",
    "model = BertForSequenceClassification.from_pretrained(trained, num_labels=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1b37d3d-0877-4e98-ac65-83cd2c566efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b1948d86214b7517\n",
      "Reusing dataset csv (/home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661d292cb35c41fc80ec3205d77d06ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Read MIMIC notes\n",
    "# notes = pd.read_csv(cfg.data.mimic_data_dir + \"NOTEEVENTS.csv\")\n",
    "\n",
    "# create hf Dataset\n",
    "classes = ['Not Relevant', 'Neither', 'Indirect', 'Direct']\n",
    "\n",
    "# instead we will use the raw text for now\n",
    "features = Features({\n",
    "    'ROW ID':Value(\"int64\"),\n",
    "    'HADM ID':Value(\"int64\"),\n",
    "    'Assessment':Value(\"string\"),\n",
    "    'Plan Subsection':Value(\"string\"),\n",
    "    \"Relation\":Value(\"string\")\n",
    "}) \n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={\n",
    "                            \"train\":\"/home/vs428/project/n2c2/2022/Data/train.csv\",\n",
    "                            \"valid\":\"/home/vs428/project/n2c2/2022/Data/dev.csv\",\n",
    "                        },\n",
    "                       features=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87ed8874-5641-4b03-bb97-30e9218beac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].shard(num_shards=1000, index=0)\n",
    "dataset['valid'] = dataset['valid'].shard(num_shards=100, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e9025b7c-c1f7-4271-ab4f-1a6ddb45f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b43d1659b503db36.arrow\n",
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1c80317fa3b1799d.arrow\n",
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cca2bc4cceeb4c43.arrow\n",
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-711f7a4ba5235efb.arrow\n",
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bdd640fb06671ad1.arrow\n",
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0c6309579bcb99a5.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.class_encode_column(\"Relation\")\n",
    "dataset = dataset.rename_column(\"Relation\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d4464ee-a2aa-4abe-906e-daf1c190aca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /tmp/tmp2uakt6uw/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmp2uakt6uw/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /tmp/tmp2uakt6uw/added_tokens.json. We won't load it.\n",
      "loading file /tmp/tmp2uakt6uw/vocab.json\n",
      "loading file /tmp/tmp2uakt6uw/merges.txt\n",
      "loading file /tmp/tmp2uakt6uw/tokenizer.json\n",
      "loading file None\n",
      "loading file /tmp/tmp2uakt6uw/special_tokens_map.json\n",
      "loading file /tmp/tmp2uakt6uw/tokenizer_config.json\n",
      "loading configuration file /tmp/tmpsz8ohyyo/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmpsz8ohyyo/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /tmp/tmpsz8ohyyo/added_tokens.json. We won't load it.\n",
      "loading file /tmp/tmpsz8ohyyo/vocab.json\n",
      "loading file /tmp/tmpsz8ohyyo/merges.txt\n",
      "loading file /tmp/tmpsz8ohyyo/tokenizer.json\n",
      "loading file None\n",
      "loading file /tmp/tmpsz8ohyyo/special_tokens_map.json\n",
      "loading file /tmp/tmpsz8ohyyo/tokenizer_config.json\n",
      "loading configuration file /tmp/tmph7o7nzsz/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmph7o7nzsz/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /tmp/tmph7o7nzsz/added_tokens.json. We won't load it.\n",
      "loading file /tmp/tmph7o7nzsz/vocab.json\n",
      "loading file /tmp/tmph7o7nzsz/merges.txt\n",
      "loading file /tmp/tmph7o7nzsz/tokenizer.json\n",
      "loading file None\n",
      "loading file /tmp/tmph7o7nzsz/special_tokens_map.json\n",
      "loading file /tmp/tmph7o7nzsz/tokenizer_config.json\n",
      "loading configuration file /tmp/tmpk2pvmh3w/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/tmp/tmpk2pvmh3w/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /tmp/tmpk2pvmh3w/added_tokens.json. We won't load it.\n",
      "loading file /tmp/tmpk2pvmh3w/vocab.json\n",
      "loading file /tmp/tmpk2pvmh3w/merges.txt\n",
      "loading file /tmp/tmpk2pvmh3w/tokenizer.json\n",
      "loading file None\n",
      "loading file /tmp/tmpk2pvmh3w/special_tokens_map.json\n",
      "loading file /tmp/tmpk2pvmh3w/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "nlp_assessment = spacy.load(assessment_model_f, exclude=\"parser\")\n",
    "nlp_plan = spacy.load(plan_model_f, exclude=\"parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bd70f6a-4a2c-4e33-ab5e-6258d1bdaee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vs428/.cache/huggingface/datasets/csv/default-b1948d86214b7517/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3eb13b9046685257.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d19794049ef4ddebe808663e407adb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ysm/project/rtaylor/vs428/conda_envs/n2c2_env/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664014bb4b85458a9706ec402aabbc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032d6a72164742ab99be5583226cc515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the named entities\n",
    "dataset['train'] = dataset['train'].map(partial(add_ner_assessment, nlp=nlp_assessment))\n",
    "dataset['train'] = dataset['train'].map(partial(add_ner_plan, nlp=nlp_plan))        \n",
    "\n",
    "dataset['valid'] = dataset['valid'].map(partial(add_ner_assessment, nlp=nlp_assessment))\n",
    "dataset['valid'] = dataset['valid'].map(partial(add_ner_plan, nlp=nlp_plan))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "339b3997-fd9a-40c8-a3a9-4ff519b1c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we ASSUME that the ner labels we want are lowercase, UNLIKE the standard ones in the model\n",
    "spans = [x for x in nlp_plan.get_pipe(\"ner\").labels if x.islower()] + [x for x in nlp_assessment.get_pipe(\"ner\").labels if x.islower()]\n",
    "\n",
    "tokens = []\n",
    "for span in spans:\n",
    "    tokens.append(\"<\" + span + \">\")\n",
    "    tokens.append(\"</\" + span + \">\")            \n",
    "\n",
    "# add the span tags to the vocab\n",
    "_ = tokenizer.add_tokens(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "581d8ec9-83c9-46f0-b3d8-224b5ec1a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complication_related_to_problem',\n",
       " 'event_related_to_problem',\n",
       " 'organ_failure_related_to_problem',\n",
       " 'problem']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in nlp_plan.get_pipe(\"ner\").labels if x.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f7b4396-ecd3-41af-b85a-a6c14d58df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f192809-ea25-4466-b905-37cb0b312d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# arguments for Trainer\n",
    "test_args = TrainingArguments(\n",
    "    output_dir = \"test_output\",\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = 4,   \n",
    "    dataloader_drop_last = False    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8694420d-e9b9-4fa1-8c39-069ba874949b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d400e2c1fbd414c8ee03b4158b117f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6b46ad2f7d4f69953a407f24d4eb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] a 60 year old woman with <secondary_problem> recurrent all </secondary_problem> with <secondary_problem> cns involvement </secondary_problem> s / p omaya removal due to <primary_problem> vre contamination </primary_problem> & <primary_problem> sdh evacuation </primary_problem>. she is now doing well and <primary_symptom> awake </primary_symptom> s / p extubation, <primary_problem> afebrile </primary_problem> and her wbc count is trending downward. [SEP] <problem> cns vre </problem> : s / p omaya removal, on linezolid for greater cns penetration despite risk of cns penetration. no tee performed. - continue linezolid ( d1 = [ * * 4 - 16 * * ] ), course to be determined by tee ( 4 vs 8 weeks ) gentamicin d / c d per id - f / u culture data and sensitivities - tee deferred at this time. - f / u tigacycline sensitivities for long - term therapy [SEP]\n",
      "[CLS] the patinet is a [ * * age over 90 * * ] year old female with a history of <secondary_problem> hypertension </secondary_problem> and <secondary_problem> urosepsis </secondary_problem> presenting with <primary_problem> altered mental status </primary_problem>, found to be <primary_problem> hypotensive </primary_problem>, <primary_problem> bradycardic </primary_problem>, and <primary_problem> hyperkalemic </primary_problem> in the setting of <primary_problem> arf </primary_problem> [SEP] # <problem> bradycardia </problem> : likely secondary to <event_related_to_problem> hyperkalemia </event_related_to_problem> w / peaked t waves and junctional <event_related_to_problem> bradycardia </event_related_to_problem>. also, may be secondary to atentolol toxicity in the setting of arf. wouldn t be surprised if has underlying sick sinus as well given advanced age. currently normal sinus w / o ekg abnormalities. - - hold atenolol - - continue potassium manegment as below. [SEP]\n",
      "[CLS] ascending cholangitis, <primary_problem> sepsis </primary_problem>. [SEP] <problem> lll infiltrate </problem> - - possible aspiration in setting of ercp. monitor. fluids - - euvolemic. monitor i / o. maintain balance. [SEP]\n",
      "[CLS] 45 year old man with pmh significant for <secondary_problem> type i dm </secondary_problem>, <secondary_problem> esrd </secondary_problem> on hemodialysis, <secondary_problem> labile blood pressure </secondary_problem>, presenting with <primary_problem> hypertensive emergency </primary_problem>. [SEP] # ) <problem> flank pain </problem> : chronic, attributed to <event_related_to_problem> diabetic peripoheral neuropathy </event_related_to_problem>. will continue gabapentin, lidocaine patch, and percocet. [SEP]\n",
      "[CLS] 79yo f with <secondary_problem> dchf </secondary_problem> ( 75 %, [ * * 3 - 26 * * ] ), <secondary_problem> cad </secondary_problem> ( rca stent'[ * * 04 * * ], <primary_problem> lcx bms </primary_problem> in'[ * * 23 * * ] ), <secondary_problem> a - fib </secondary_problem>, <secondary_problem> htn </secondary_problem>, <secondary_problem> dm2 </secondary_problem>, <secondary_problem> esrd </secondary_problem> on hd, <secondary_problem> cryptogenic cirrhosis </secondary_problem> with variceal bleeding ( s / p banding'[ * * 25 * * ] ) and <primary_problem> lgib </primary_problem> ( divericulosis, angiectasia'[ * * 23 * * ] ) admitted with <primary_problem> intertrochanteric femoral fracture </primary_problem> after fall at home s / p <primary_problem> orif </primary_problem> c / b post - op hypotension and is transfered to micu for close observation. [SEP] esrd on hd t / th / sat : last hd prior to orif ; cre today 1. 1. [SEP]\n",
      "[CLS] <primary_problem> achycardia, other </primary_problem> <primary_problem> gastrointestinal bleed, lower ( hematochezia, brbpr, gi bleed, gib ) </primary_problem> 76 - year - old man with history of <secondary_problem> diverticulosis </secondary_problem>, <secondary_problem> prostate cancer </secondary_problem>, <secondary_problem> stroke </secondary_problem> on aggrenox, <secondary_problem> dm2 </secondary_problem>, <secondary_problem> hypertension </secondary_problem> presented with <primary_problem> brbpr </primary_problem>, most likely <primary_problem> diverticular bleeding </primary_problem>. [SEP] # <problem> svt </problem> : likely avnrt, easy to break with vagal maneuvers, continue lopressor 25mg po tid, uptitrate if necessary. he has a history of this and his outpt cardiologist has been aware of this. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# metrics to track\n",
    "acc = load_metric(\"accuracy\")\n",
    "macrof1 = load_metric(\"f1\")    \n",
    "\n",
    "# create metric_dict for compute_metrics\n",
    "metric_dict = {}\n",
    "metric_dict['accuracy'] = {\"metric\":acc}\n",
    "metric_dict['f1-macro'] = {\"metric\":macrof1, \"average\":\"macro\"}\n",
    "\n",
    "# tokenize\n",
    "dataset = dataset.map(partial(tokenize_function, tokenizer=tokenizer), batched=True)\n",
    "\n",
    "print(tokenizer.decode(dataset['valid'][0]['input_ids']))\n",
    "print(tokenizer.decode(dataset['valid'][1]['input_ids']))\n",
    "print(tokenizer.decode(dataset['valid'][2]['input_ids']))\n",
    "print(tokenizer.decode(dataset['valid'][3]['input_ids']))\n",
    "print(tokenizer.decode(dataset['valid'][4]['input_ids']))\n",
    "print(tokenizer.decode(dataset['valid'][5]['input_ids']))\n",
    "\n",
    "\n",
    "# cast as pytorch tensors and select a subset of columns we want\n",
    "dataset['train'].set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "dataset['valid'].set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])    \n",
    "\n",
    "# create collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer,\n",
    "                                        max_length=512, \n",
    "                                        padding=\"max_length\",\n",
    "                                        return_tensors=\"pt\")    \n",
    "# create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    compute_metrics=partial(compute_metrics, metric_dict=metric_dict),\n",
    "    data_collator=data_collator,\n",
    ")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2012b4d9-e88d-4a89-9d6f-29da7fe25970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: ROW ID, HADM ID, Assessment, Plan Subsection. If ROW ID, HADM ID, Assessment, Plan Subsection are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# train!!\n",
    "test_results = trainer.predict(dataset['valid'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "804b4fee-1c98-48ba-aaa4-68a6abe8a88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 6.9185734 , -0.92201823, -2.8100662 , -3.7802644 ],\n",
       "       [ 6.7194004 , -0.7142646 , -2.694345  , -3.913022  ],\n",
       "       [-2.1814272 ,  5.987942  , -1.461201  , -4.5394278 ],\n",
       "       [-2.4529886 , -0.26281548,  7.107601  , -3.6556134 ],\n",
       "       [-2.7313566 ,  6.190248  , -1.3259091 , -4.2794614 ],\n",
       "       [-1.9983196 , -0.57214653,  6.907893  , -3.3900998 ]],\n",
       "      dtype=float32), label_ids=array([0, 0, 1, 2, 1, 1]), metrics={'test_loss': 1.2473772764205933, 'test_accuracy': {'accuracy': 0.8333333333333334}, 'test_f1-macro': {'f1': 0.8222222222222223}, 'test_runtime': 7.8954, 'test_samples_per_second': 0.76, 'test_steps_per_second': 0.253})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f173a9f-8036-4dc2-9818-65bb7a2dc9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['valid']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7bc820d-4c78-4370-a596-09c47c7577a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test_results.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6993919-d7c4-428a-a197-1ea7c274e469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([    2, 30530,  3546, 14557,    16,  2303, 30531, 30530,  8375,  6189,\n",
       "          1919,    16,  2826,    12,  5626,  2694, 11788,  2126,    16,  2387,\n",
       "          3846,  1005,    16,  7217,  6189,  1919,    16, 10122,    13, 30531,\n",
       "          5439,    17,  2476,    17,  4156,  2323,  1956,  4403,  1927, 30536,\n",
       "         24078,  8071, 30537,    16, 30536,  5683,  2539, 30537,    16, 30536,\n",
       "          5235, 30537,  1990,  6434, 19824,  1039,    16, 30536,  3931,  1028,\n",
       "         30537,    16, 30536,  5579, 30537,  3549,  1956, 30530,  2387,  3846,\n",
       "          1005, 30531,    16,  2501,  3205, 30530, 24078,  2168,  7633, 30531,\n",
       "            18,     3,     7, 30528,  6456,  1031, 30529,    30,  3205,  2781,\n",
       "         16964,  1031,    16,  9040,  1942,  6017,  1956, 20653, 27576,  1036,\n",
       "            16,  9085,  3004, 29079,  2637,  9759,  2510,  8685,  1007,    16,\n",
       "          2353,  2572,  5524,  2057,  2647,  4680,    18,  2234,  2258,    43,\n",
       "          4403,  1927,  2052,  1930,  4167,  2397,  2410, 21129, 22284,  2184,\n",
       "          2258,  2252, 11207,  1927,  2052,    18,     3]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['valid'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2bd0fe-8ed1-4461-a546-eb0eca036645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87d805-3b33-4cc8-93a0-470f15230e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dfc7be-83b3-46c7-ac26-a64eb18ca29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c81e26-e01f-4923-819d-05be9d234765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
